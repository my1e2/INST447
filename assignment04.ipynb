{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "your_name = \"Myles Sartor\"\n",
        "your_uid = \"119017708\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 04: Data Quality\n",
        "\n",
        "This assignment explores how data quality issues can lead to misleading conclusions. You'll simulate datasets, reproduce biased results, and test whether AI can spot the issues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 1: Simpson's Paradox - Berkeley Admissions\n",
        "\n",
        "In 1973, UC Berkeley was sued for gender discrimination. Aggregate data showed men had higher admission rates. But within each department, women had equal or higher rates. This is an example of **Simpson's Paradox**: Men applied to high-acceptance departments; women to low-acceptance ones.\n",
        "\n",
        "Let's first create a synthetic dataset simulating the students' application and admission status.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulation parameters\n",
        "n_applicants = 10000\n",
        "n_departments = 6\n",
        "department_acceptance_rates = [0.64, 0.63, 0.35, 0.34, 0.24, 0.07]  # High to low acceptance\n",
        "male_application_dist = [0.31, 0.21, 0.12, 0.16, 0.07, 0.13]  # Men favor high-acceptance depts\n",
        "female_application_dist = [0.02, 0.01, 0.27, 0.17, 0.24, 0.29]  # Women favor low-acceptance depts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 5000 male applicants and 5000 female applicants\n",
            "\n",
            "Male department distribution:\n",
            "0    1574\n",
            "1    1035\n",
            "2     599\n",
            "3     793\n",
            "4     359\n",
            "5     640\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Female department distribution:\n",
            "0      98\n",
            "1      42\n",
            "2    1382\n",
            "3     895\n",
            "4    1214\n",
            "5    1369\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Generate department choices for each gender\n",
        "n_males = n_applicants // 2\n",
        "n_females = n_applicants - n_males\n",
        "\n",
        "# Men choose departments based on male_application_dist\n",
        "male_depts = np.random.choice(n_departments, size=n_males, p=male_application_dist)\n",
        "\n",
        "# Women choose departments based on female_application_dist\n",
        "female_depts = np.random.choice(n_departments, size=n_females, p=female_application_dist)\n",
        "\n",
        "print(f\"Generated {n_males} male applicants and {n_females} female applicants\")\n",
        "print(f\"\\nMale department distribution:\")\n",
        "print(pd.Series(male_depts).value_counts().sort_index())\n",
        "print(f\"\\nFemale department distribution:\")\n",
        "print(pd.Series(female_depts).value_counts().sort_index())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Admission decisions made!\n"
          ]
        }
      ],
      "source": [
        "# Determine admission for each applicant\n",
        "# Same acceptance rates for both genders (no discrimination at dept level)\n",
        "male_admitted = (np.random.random(n_males) < np.array(department_acceptance_rates)[male_depts]).astype(int)\n",
        "female_admitted = (np.random.random(n_females) < np.array(department_acceptance_rates)[female_depts]).astype(int)\n",
        "\n",
        "print(\"Admission decisions made!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset created!\n",
            "  gender  department  admitted\n",
            "0   Male           1         1\n",
            "1   Male           5         0\n",
            "2   Male           3         1\n",
            "3   Male           2         0\n",
            "4   Male           0         1\n",
            "5   Male           0         0\n",
            "6   Male           0         1\n",
            "7   Male           4         0\n",
            "8   Male           2         0\n",
            "9   Male           3         0\n"
          ]
        }
      ],
      "source": [
        "# Combine everything into a DataFrame\n",
        "df_berkeley = pd.DataFrame({\n",
        "    'gender': ['Male'] * n_males + ['Female'] * n_females,\n",
        "    'department': np.concatenate([male_depts, female_depts]),\n",
        "    'admitted': np.concatenate([male_admitted, female_admitted])\n",
        "})\n",
        "\n",
        "print(\"Dataset created!\")\n",
        "print(df_berkeley.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregate vs. Stratified Rates\n",
        "\n",
        "Compute admission rates two ways:\n",
        "\n",
        "1. **Aggregate:** Overall rate by gender \n",
        "2. **Stratified:** Rate by gender WITHIN each department \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aggregate Admission Rates (overall rate by gender):\n",
            "gender\n",
            "Female    0.2428\n",
            "Male      0.4564\n",
            "Name: admitted, dtype: float64\n",
            "\n",
            "Stratified Admission Rates (Rate by gender within each department):\n",
            "gender        Female      Male\n",
            "department                    \n",
            "0           0.632653  0.632783\n",
            "1           0.642857  0.650242\n",
            "2           0.335745  0.355593\n",
            "3           0.310615  0.351828\n",
            "4           0.228995  0.231198\n",
            "5           0.076698  0.059375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# Aggregate rates\n",
        "aggregate_rates = df_berkeley.groupby('gender')['admitted'].mean()\n",
        "print(\"Aggregate Admission Rates (overall rate by gender):\")\n",
        "print(aggregate_rates)\n",
        "print()\n",
        "\n",
        "# Stratified rates\n",
        "stratified_rates = df_berkeley.groupby(['department', 'gender'])['admitted'].mean().unstack()\n",
        "print(\"Stratified Admission Rates (Rate by gender within each department):\")\n",
        "print(stratified_rates)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did you reproduce the Simpson's Paradox? \n",
        "\n",
        "Yes, the Simpson's Paradox was reproduced and showcased after aggregation and stratification of the given dataset. Although men have a higher overall average admission rate at 39.26 % while women have one at 29.02 %, the individual departments revealed that women have similar or higher admission rates in most departments. The gender bias that one might assume to be there ends up disappearing when we control for departments. This is quite surprising, especially during this time period when the data was first acquired. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 2: Selection Bias - Wage Data\n",
        "\n",
        "When wages are only observed for people who work, missingness is informative. People with higher potential wages are more likely to work (self selection bias).\n",
        "\n",
        "Let's begin by creating a synthetic dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated 5000 true wages\n",
            "Mean: $50,226.81\n",
            "Std: $15,047.34\n",
            "Participation rate: 79.38%\n",
            "Number of participants: 3969\n",
            "Number of non-participants: 1031\n",
            "Dataset created!\n",
            "      true_wage  reservation_wage  participated  observed_wage\n",
            "0  37942.952299      40331.551745             1   37942.952299\n",
            "1  58789.876535      30544.396782             1   58789.876535\n",
            "2  69594.207136      30422.382772             1   69594.207136\n",
            "3  31596.264856      30464.442285             1   31596.264856\n",
            "4  75684.615926      35984.048365             1   75684.615926\n",
            "5  48071.734484      25130.898616             1   48071.734484\n",
            "6  35374.679226      32646.688101             1   35374.679226\n",
            "7  61366.321703      40152.173946             1   61366.321703\n",
            "8  43303.182826      38304.599564             1   43303.182826\n",
            "9  48773.949860      33193.647720             0            NaN\n"
          ]
        }
      ],
      "source": [
        "# Simulation parameters\n",
        "n_population = 5000\n",
        "true_wage_mean = 50000\n",
        "true_wage_std = 15000\n",
        "reservation_wage_mean = 35000\n",
        "reservation_wage_std = 5000\n",
        "selection_correlation = 0.2  # How correlated are true_wage and reservation_wage\n",
        "\n",
        "# Generate true wages (what each person would earn if they worked)\n",
        "true_wages = np.maximum(np.random.normal(true_wage_mean, true_wage_std, n_population), 0)\n",
        "\n",
        "print(f\"Generated {n_population} true wages\")\n",
        "print(f\"Mean: ${true_wages.mean():,.2f}\")\n",
        "print(f\"Std: ${true_wages.std():,.2f}\")\n",
        "\n",
        "# Generate reservation wages (minimum wage person would accept to work)\n",
        "# Has some correlation with true_wage, but also independent component\n",
        "reservation_base = np.random.normal(reservation_wage_mean, reservation_wage_std, n_population)\n",
        "reservation_correlated = reservation_wage_mean + selection_correlation * (true_wages - true_wage_mean) * (reservation_wage_std / true_wage_std)\n",
        "reservation_wages = np.maximum(reservation_base * 0.7 + reservation_correlated * 0.3, 0)\n",
        "\n",
        "# Determine Participation\n",
        "# People participate (work) if their true_wage >= reservation_wage. \n",
        "# Higher earners are more likely to participate, but it's probabilistic (not guaranteed):\n",
        "\n",
        "wage_gap = true_wages - reservation_wages\n",
        "participation_prob = 1 / (1 + np.exp(-wage_gap / 5000))  # Sigmoid function\n",
        "participation_prob = np.clip(participation_prob, 0.05, 0.95)  # Cap between 5% and 95%\n",
        "participated = (np.random.random(n_population) < participation_prob).astype(int)\n",
        "\n",
        "print(f\"Participation rate: {participated.mean():.2%}\")\n",
        "print(f\"Number of participants: {participated.sum()}\")\n",
        "print(f\"Number of non-participants: {(participated == 0).sum()}\")\n",
        "\n",
        "# Create observed_wage\n",
        "# We only observe wages for people who participated. \n",
        "# Non-participants have missing values (NaN):\n",
        "observed_wages = np.where(participated == 1, true_wages, np.nan)\n",
        "\n",
        "# Combine into DataFrame\n",
        "df_wages = pd.DataFrame({\n",
        "    'true_wage': true_wages,\n",
        "    'reservation_wage': reservation_wages,\n",
        "    'participated': participated,\n",
        "    'observed_wage': observed_wages\n",
        "})\n",
        "\n",
        "print(\"Dataset created!\")\n",
        "print(df_wages.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We have created a visualization to show the the true wage distribution, and the hypothetical distribution if you treat missing values with the naive fixes. You may clearly see that by removing missing value (middle panel), the observed wages is right skewed and the estimated mean is higher than the true mean. However, if we replace missing value with 0, there would be a artificial spike at 0 and the estimated mean is lower than the true mean.  \n",
        "\n",
        "![Basic visualization](https://raw.githubusercontent.com/aiwei/course-umd/main/data/assignment04_part2_vis.png)\n",
        "\n",
        "In the cells below, please calcuate the average wage using the two naive fixes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True mean: $50,226.81\n",
            "dropna() mean: $54,273.64 (bias: +$4,046.83)\n",
            "fillna(0) mean: $43,082.42 (bias: $-7,144.39)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CODE HERE\n",
        "# naive fix 1: dropna\n",
        "dropna_mean = df_wages['observed_wage'].dropna().mean() # YOUR CODE: mean of observed_wage after dropna()\n",
        "\n",
        "# naive fix 2: fillna(0)\n",
        "fillna_mean = df_wages['observed_wage'].fillna(0).mean() # YOUR CODE: mean of observed_wage after fillna(0)\n",
        "\n",
        "# Compare with true mean\n",
        "true_mean = df_wages['true_wage'].mean()\n",
        "print(f\"True mean: ${true_mean:,.2f}\")\n",
        "print(f\"dropna() mean: ${dropna_mean:,.2f} (bias: +${dropna_mean-true_mean:,.2f})\")\n",
        "print(f\"fillna(0) mean: ${fillna_mean:,.2f} (bias: ${fillna_mean-true_mean:,.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PART 3: Testing Your AI Assistant\n",
        "\n",
        "Now, let's see if AI Assistant can spotify these issues and help us correct them. You may try the following prompts with your favorite (or least favorite) AI Chatbot:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3A: Naive Questions (No Context)\n",
        "\n",
        "Ask AI **WITHOUT** mentioning how data was generated:\n",
        "\n",
        "**Berkeley Prompt (This prompt purposefully ignored the availability of department information.):**\n",
        "\n",
        "```\n",
        "I have admissions data, that look like the following and I am analyzing whether there are gender discrimination in the admission process. Help me create a data analysis plan.\n",
        "\n",
        "gender admitted\n",
        "0   Male 0\n",
        "1   Male 0\n",
        "2   Male 0\n",
        "3   Male 0\n",
        "4   Male 1\n",
        "5   Female 0\n",
        "6   Female 0\n",
        "7   Female 1\n",
        "8   Female 0\n",
        "9   Female 1\n",
        "```\n",
        "\n",
        "**Question**\n",
        "\n",
        "How did LLM respond? It is very likely that the latest models have been trained to master the knowledge of Simpson's Paradox, and may even ask \"do you have other information like department, if so, you may encounter Simpson's Paradox\". Yet you may still need to see the detailed language LLM used in bringing up Simpson's Paradox. -- Did LLM merely mention that \"you will see different or reverse result, or did LLM try to reason what is the right conclusion? Did LLM discuss from the data generation perspective?\n",
        "\n",
        "**Wages Prompt:**\n",
        "\n",
        "```\n",
        "I would like to study women's wage in the labor market, what is their mean wage and what is the impact factor of their wage. I have data that look like the following\n",
        "\n",
        " wage, education, chilren_in_family, age\n",
        "0, 1000, \"high-school\", 0, 30\n",
        "1, NA, \"bachelor\", 2, 35\n",
        "2, 1000, \"post-graduate\", 1, 27\n",
        "\n",
        "My first step is to calculate the mean wage of the population, how should I do that.\n",
        "\n",
        "```\n",
        "\n",
        "**Question**\n",
        "\n",
        "How did LLM respond. You may want to pay attention to the following perspective:\n",
        "1. Did LLM notice missing values in the dataset.\n",
        "2. Did LLM offered solutions (dropna, fillna) to deal with missing values, one, or both, or more?\n",
        "3. Did LLM discuss how they may impact/bias the estimated mean, in what direction?\n",
        "4. Did LLM offer more comprehensive plan tackle the missing value issue? \n",
        "\n",
        "Please put your **answers** as well as your reflection in the next two cells. Please do **NOT** paste the AI's response. Intead, summarize what LLM says and misses in your own language. \n",
        "\n",
        "**please note that this summarization should be your own words, and we reserve the right to penalize answers that does not comply with this requirement**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Your Response to the first case study (Berkeley):**\n",
        "\n",
        "The LLM provided me with a plan that incorporated a standardized research question before beginning to help me inspect and clean the data for exploratory data analysis. With the question being focused around the differences that may exist in admission rates between male and female applicants, visualizations of bar charts grouped by gender for counts and rates were suggested as powerful measures of disparity. Once getting past plots and descriptive statistics, chi-squre statistical testing of independence was utilized to determine if gender is independent of admissions since these two variables were categorical in nature. Even with all this, an effect size odds ratio, and logistic regression, the LLM still urged me to check for Simpson's Paradox, as it deemed it to be the most important detail in the process. In citing real admission discrimination cases such as the famous one from UC Berkeley, it realized that aggregated data may show gender differences when each department has the pattern reversing. The summarized conclusions and interpretations could be associated with statistically significant differences in admission rates due to chance or confounding variables, but not malicious intent.\n",
        "\n",
        "**Your Response to the second case study (Wage):**\n",
        "\n",
        "1. The missing values were initially the first aspect about the given data that the LLM noticed, remarking that I needed to decide what I wanted to do with them. \n",
        "\n",
        "2. Upon noticing the mising data, the LLM gave me two options. The first being the choice of excluding missing wages altogether, stating that it would be a standard and reccomended approach in labor economics unless there's valid reasoning to do something else. The other option dealt with simply imputing the missing wages if justified, as the mean, median, and regression model could all aid in determining what exact values to originally input. \n",
        "\n",
        "3. The LLM mentioned the dangers of imputing data blindly or with no intentions of creating a reliable model in the future, since the regression results can later be biased as a result of this. In this case, the model might end up understating what wages truly deserve to be (negative direction) if the values replacing missing observations are too low (or if the presence of them is too high).   \n",
        "\n",
        "4. The LLM offered a well-thought out plan that handled missing wage values in the pandas dataframe with code that skipped over them in average wage calculations using synthetic data as an example for the given situation. Exploring wage inequalities across groups and running regression analysis to find wage impact factors (education, age, children) appeared to be the next steps that it was going to take in building a complete data analysis plan for this pseudo-proejct. \n",
        "\n",
        "\n",
        "**Your Reflection -- What do you think AI do well and do poorly, how does that affect your own use of AI in data analysis?**\n",
        "\n",
        "AI does really well at explaining things and recognizing patterns from data and scenarios that it has been trained on, especially as it concerns common data science problems that will undoubtedly show up and have shown up in the real world. As a result, it can easily offer solutions that are comprehensive enough to be valuable approaches that utilize concepts and statistical ideas clearly. However, as the problem gets more complicated and the level of information given to an LLM is scarce, its means of judgement and reasoning can suffer without proper guidance for the given context. With this lack of real-world understanding behind the numerical situations it can analyze, the data generation often leaves AI stuck at times. As I engage with data analysis concepts and typical exploration more and more, I've come to use AI as a tool that advances my learning in data domains that I'm already familiar with so that I can focus on what's important. By not utilizing it as a full on replacement, I can leverage what's given to me at opportune times, checking data and analysis for faults and ideas that I wouldn't have seen otherwise (Given that I frame my prompts and desires correctly). Human judgement will remain essential for understanding real-world navigations through expected results and data-driven decision-making. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission Instruction\n",
        "\n",
        "- Jupyter Notebook: File → Download as → Notebook (.ipynb)\n",
        "- Google Colab: File → Download → Download .ipynb\n",
        "- **Submit the `.ipynb` file to ELMS**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
