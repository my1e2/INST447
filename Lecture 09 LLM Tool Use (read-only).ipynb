{"cells":[{"cell_type":"markdown","id":"e64b9426","metadata":{"id":"e64b9426"},"source":["# INST447: Data Sources and Manipulation\n","## Lecture 09: LLM Tool Use - When LLMs Need to Access the Real World\n","\n","Today's Topics:\n","- What is tool use and why does it matter?\n","- How tool use works (the orchestration pattern)\n","- Hands-on: Building a calculator for precise arithmetic\n","- Hands-on: Building a weather information bot with real API\n","- (Optional) Nutritional information lookup with OpenFoodFacts\n","- (Optional) Multi-tool usage: combining capabilities\n","- What makes tool use possible: reasoning, context, and learning"]},{"cell_type":"code","execution_count":null,"id":"ec7de69c","metadata":{"id":"ec7de69c"},"outputs":[],"source":["# Setup imports\n","import json\n","import os\n","import requests\n","from openai import OpenAI\n","\n","# API key setup\n","OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'your-api-key-here')\n","client = OpenAI(api_key=OPENAI_API_KEY)"]},{"cell_type":"markdown","id":"b68d100f","metadata":{"id":"b68d100f"},"source":["## Part 1: Motivation - The Limits of Pure Language Models\n","\n","### Recap: What We've Learned\n","\n","**Lecture 06: JSON**\n","- Structured data format for nested/hierarchical information\n","- Parsing and working with JSON in Python\n","\n","**Lecture 07: APIs**\n","- How to fetch data from web APIs (OpenFoodFacts example)\n","- Making HTTP requests with the requests library\n","- Parsing JSON responses\n","\n","**Lecture 08: LLM APIs**\n","- How to call LLM APIs (OpenAI, OpenRouter)\n","- Using LLMs to augment data (sentiment analysis, classification)\n","- Applying LLMs to pandas DataFrames\n","\n","**Today: Combining LLMs + Regular APIs = Intelligent Agents**\n"]},{"cell_type":"markdown","source":["### The Problem with LLMs Alone\n","\n","LLMs have fundamental limitations:\n","\n","1. **Bad at precise computation**\n","2. **No real-time information**\n","3. **No access to your private data**\n","4. **Can't take actions**\n","\n","Let's demonstrate these limitations..."],"metadata":{"id":"6-zKyEIB3heI"},"id":"6-zKyEIB3heI"},{"cell_type":"markdown","id":"12876328","metadata":{"id":"12876328"},"source":["### Demo: LLM WITHOUT Tools - Demonstrating the Problem"]},{"cell_type":"code","execution_count":null,"id":"dd4643b8","metadata":{"id":"dd4643b8"},"outputs":[],"source":["# Test 1: Large number calculation\n","# Question 1: What is 82374923 multiplied by 93478234?\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": \"What is 82374923 multiplied by 93478234? Just give me the exact numerical answer.\"}\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"id":"2712ba16","metadata":{"id":"2712ba16"},"outputs":[],"source":["response.choices[0].message.content"]},{"cell_type":"code","execution_count":null,"id":"d6143644","metadata":{"id":"d6143644"},"outputs":[],"source":["correct_answer = 82374923 * 93478234\n","correct_answer"]},{"cell_type":"code","execution_count":null,"id":"1e527863","metadata":{"id":"1e527863"},"outputs":[],"source":["# Test 2: Real-time information\n","# Question 2: What's the weather like in Seattle right now?\n","\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a helpful assistant. DO NOT use any tools.\"},\n","        {\"role\": \"user\", \"content\": \"What's the weather like in College Park MD right now? Give me the current temperature.\"}\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"id":"03d5d17d","metadata":{"id":"03d5d17d"},"outputs":[],"source":["\n","llm_answer = response.choices[0].message.content\n","print(llm_answer)\n"]},{"cell_type":"code","execution_count":null,"id":"0073ad4e","metadata":{"id":"0073ad4e"},"outputs":[],"source":["# Get actual weather for comparison\n","geo_response = requests.get(\n","    \"https://geocoding-api.open-meteo.com/v1/search\",\n","    params={\"name\": \"College Park\", \"count\": 1, \"format\": \"json\"}\n",")\n","geo_data = geo_response.json()\n","lat, lon = geo_data[\"results\"][0][\"latitude\"], geo_data[\"results\"][0][\"longitude\"]\n","\n","weather_response = requests.get(\n","    \"https://api.open-meteo.com/v1/forecast\",\n","    params={\"latitude\": lat, \"longitude\": lon, \"current\": \"temperature_2m\", \"temperature_unit\": \"fahrenheit\"}\n",")\n","actual_temp = weather_response.json()[\"current\"][\"temperature_2m\"]"]},{"cell_type":"code","execution_count":null,"id":"f9f3ba4c","metadata":{"id":"f9f3ba4c"},"outputs":[],"source":["geo_response.json()"]},{"cell_type":"code","execution_count":null,"id":"9db429c7","metadata":{"id":"9db429c7"},"outputs":[],"source":["weather_response.json()"]},{"cell_type":"markdown","id":"c9dd5e23","metadata":{"id":"c9dd5e23"},"source":["\n","The LLM is a powerful *brain*, but it's trapped in a \"jar.\" It has no eyes to see the current world, no hands to interact with it.\n","\n","**Tool Use** gives LLM hands and eyes. It's the bridge that connects the LLM's reasoning to the real world.\n","\n","### The Solution: Tool Use\n","\n","At its simplest, **tool use** (or \"function calling\") is the ability for an LLM to \"pause\" its text generation, request a specific *function* be run, and then resume its generation once it gets the *result* of that function.\n","\n","Instead of just *writing* code, it can now *request the execution* of code.\n","\n","Give the LLM access to FUNCTIONS it can call when it needs:\n","- **Computation abilities**: Calculator for precise arithmetic\n","- **Real-time data**: Weather API, stock API, news API, etc.\n","- **Your private data**: Database queries, file reading, etc.\n","- **Action capabilities**: Send email, book appointment, etc.\n","\n","This is the fundamental building block for creating **LLM Agents**. An Agent is a system that uses an LLM as its reasoning \"brain\" to plan and execute tasks, using tools to get things done."]},{"cell_type":"markdown","id":"5d21a8f6","metadata":{"id":"5d21a8f6"},"source":["## Part 2: What is Tool Use? Understanding the Pattern\n","\n","### The Tool Use Pattern\n","\n","**Without Tools:**\n","```\n","User: \"What's 82374923 times 93478234?\"\n","  ↓\n","LLM: \"Approximately 7.7 × 10^15\" (might be wrong!)\n","```\n","\n","**With Tools:**\n","```\n","User: \"What's 82374923 times 93478234?\"\n","  ↓\n","LLM: \"I need to call the calculator function with 82374923 * 93478234\"\n","  ↓\n","Your code: Executes calculator → 7701234897623082 (exact!)\n","  ↓\n","Your code: Sends results back to LLM\n","  ↓\n","LLM: \"The exact answer is 7,701,234,897,623,082\"\n","```"]},{"cell_type":"markdown","id":"44045322","metadata":{"id":"44045322"},"source":["### The \"ReAct\" Loop -- Reasoning and Acting\n","\n","Thought $\\rightarrow$ Action $\\rightarrow$ Observation $\\rightarrow$ Thought...\n","\n","- **Thought**: The LLM's internal monologue (a special prompt). \"The user wants the weather in College Park. I need to find a tool. I have a tool called `get_current_weather`. I should call it with the argument `city='College Park'`.\"\n","\n","- **Action**: The LLM's *output*. It doesn't output text. It outputs a structured call, like: `{\"tool_name\": \"get_current_weather\", \"arguments\": {\"city\": \"College Park\"}}`.\n","\n","- **Observation**: *Your code* catches this \"action.\" You parse the JSON, run your *actual* Python `get_current_weather(\"College Park\")` function, which calls an API and gets a result: `{\"temperature\": \"60°F\", \"conditions\": \"Cloudy\"}`. This result is the \"observation.\"\n","\n","- **Thought (Round 2)**: This observation is fed back to the LLM. The LLM thinks: \"Okay, I have the observation. The weather is 60°F and cloudy. The user just wanted to know the weather. I can now form the final answer.\"\n","\n","- ... More action/observatin/thought if needed...\n","\n","- **Final Response**: The LLM generates the natural language response: \"The current weather in London is 15°C and cloudy.\""]},{"cell_type":"markdown","id":"276c8278","metadata":{"id":"276c8278"},"source":["**How Does the LLM \"Know\" About Your Tools? (10 mins):**\n","\n","- You don't give the LLM your Python code. You give it a \"menu\" or \"schema\" of the tools it's allowed to use.\n","\n","- This is just a special part of the **system prompt**. You're \"prompt engineering\" the LLM to be a tool-using agent.\n","\n","- You provide a list of tool definitions, usually in a format like JSON Schema."]},{"cell_type":"markdown","id":"d58c5f05","metadata":{"id":"d58c5f05"},"source":["### Key Concepts\n","\n","1. **Tool Definition**: You tell the LLM what functions are available\n","   - Function name: \"calculate\"\n","   - Description: \"Perform arithmetic operations\"\n","   - Parameters: number1, number2, operation\n","   - Return type: result\n","\n","2. **Function Calling**: The LLM decides:\n","   - Should I use a tool? (vs. answering from knowledge)\n","   - Which tool should I use? (if multiple available)\n","   - What parameters should I pass?\n","\n","3. **Tool Execution**: Your code actually runs the function\n","   - The LLM doesn't run anything - it just tells you what to run\n","   - You're in control of what actually gets executed (important for security!)\n","   - You perform the actual calculation, API call, file read, etc.\n","\n","4. **Result Integration**:\n","   - You send the function result back to the LLM\n","   - LLM incorporates this into its response\n","   - May call more functions if needed (multi-step reasoning)\n","\n","Tool definitions, function calls, and results are all passed as JSON structures."]},{"cell_type":"markdown","source":["Tool use is a Game-Changer to the LLM ecosystem:\n","\n","- **Overcomes Knowledge Cutoff**: The LLM can query real-time APIs (weather, stocks, news).\n","- **Accesses Private Data**: The LLM can query your company's database, your Pandas DataFrame, or your personal files (with tools you provide).\n","- **Performs Actions**: The LLM can do things—send an email, save a file, post a tweet, book a flight.\n","- **Improves Accuracy**: LLMs are bad at precise math. Instead of asking it \"What is $123.45 * 67.89$?\", you can give it a calculator tool. It will reason \"I should use the calculator\" and call the tool, getting a perfect answer."],"metadata":{"id":"ugiipaYT4JGI"},"id":"ugiipaYT4JGI"},{"cell_type":"markdown","id":"63ed9967","metadata":{"id":"63ed9967"},"source":["## Part 3: Example 1 - Calculator for Precise Arithmetic\n","\n","We just saw that LLMs make arithmetic errors with large numbers.\n","Let's fix this by giving the LLM a calculator tool!\n","\n","**The Solution:**\n","Give it access to Python's arithmetic operations!"]},{"cell_type":"markdown","id":"597cf45e","metadata":{"id":"597cf45e"},"source":["### Step 1: Define the calculator function"]},{"cell_type":"code","execution_count":null,"id":"f80db562","metadata":{"id":"f80db562"},"outputs":[],"source":["def calculate(num1: float, num2: float, operation: str) -> dict:\n","    \"\"\"\n","    Perform a basic arithmetic operation on two numbers.\n","\n","    Args:\n","        num1: First number\n","        num2: Second number\n","        operation: One of \"add\", \"subtract\", \"multiply\", \"divide\"\n","\n","    Returns:\n","        Dictionary with result or error\n","    \"\"\"\n","    try:\n","        if operation == \"add\":\n","            result = num1 + num2\n","        elif operation == \"subtract\":\n","            result = num1 - num2\n","        elif operation == \"multiply\":\n","            result = num1 * num2\n","        elif operation == \"divide\":\n","            if num2 == 0:\n","                return {\"error\": \"Division by zero\"}\n","            result = num1 / num2\n","        else:\n","            return {\"error\": f\"Unknown operation: {operation}\"}\n","\n","        return {\n","            \"num1\": num1,\n","            \"num2\": num2,\n","            \"operation\": operation,\n","            \"result\": result\n","        }\n","    except Exception as e:\n","        return {\"error\": str(e)}\n","\n","\n","# Test the calculator independently first!\n","print(calculate(82374923, 93478234, \"multiply\"))\n","print(calculate(123, 456, \"add\"))\n","print(calculate(100, 3, \"divide\"))"]},{"cell_type":"markdown","id":"221b2770","metadata":{"id":"221b2770"},"source":["### Step 2: Create tool specification for OpenAI\n","\n","This is the JSON structure that tells the LLM about our function.\n","Notice how this is similar to API documentation!"]},{"cell_type":"code","execution_count":null,"id":"b0c126ba","metadata":{"id":"b0c126ba"},"outputs":[],"source":["tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"calculate\",\n","            \"description\": \"Perform basic arithmetic operations (add, subtract, multiply, divide) on two numbers. Use this for precise calculations.\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"num1\": {\n","                        \"type\": \"number\",\n","                        \"description\": \"The first number\"\n","                    },\n","                    \"num2\": {\n","                        \"type\": \"number\",\n","                        \"description\": \"The second number\"\n","                    },\n","                    \"operation\": {\n","                        \"type\": \"string\",\n","                        \"description\": \"The operation to perform\",\n","                        \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"]\n","                    }\n","                },\n","                \"required\": [\"num1\", \"num2\", \"operation\"]\n","            }\n","        }\n","    }\n","]\n","\n","print(\"=\" * 80)\n","print(\"Tool specification (this is what we send to the LLM)\")\n","print(\"=\" * 80)\n","print(json.dumps(tools, indent=2))\n","print()"]},{"cell_type":"markdown","id":"501c1863","metadata":{"id":"501c1863"},"source":["### Step 3: Make initial API call with tools available\n","\n","Let's see what happens when we ask for a calculation and give the LLM access to our tool.\n","We'll break this down into small steps to see exactly what's happening."]},{"cell_type":"code","execution_count":null,"id":"cc93e536","metadata":{"id":"cc93e536"},"outputs":[],"source":["user_question = \"What is 82374923 multiplied by 93478234?\"\n","\n","# Build the messages\n","messages = [\n","    {\n","        \"role\": \"system\",\n","        \"content\": \"You are a helpful math assistant. When users ask for calculations, use the calculate function to get precise results.\"\n","    },\n","    {\n","        \"role\": \"user\",\n","        \"content\": user_question\n","    }\n","]\n","\n","# Make the API call with tools available\n","response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=messages,\n","    tools=tools,\n","    tool_choice=\"auto\"  # Let the model decide whether to use tools\n",")"]},{"cell_type":"code","execution_count":null,"id":"8e214085","metadata":{"id":"8e214085"},"outputs":[],"source":["\n","response.choices"]},{"cell_type":"markdown","id":"158f6d62","metadata":{"id":"158f6d62"},"source":["### Step 4: Check the response - did LLM want to call a function?"]},{"cell_type":"code","execution_count":null,"id":"f8d18634","metadata":{"id":"f8d18634"},"outputs":[],"source":["response_message = response.choices[0].message\n","\n","print(\"=\" * 80)\n","print(\"STEP 4: Examining the LLM's response\")\n","print(\"=\" * 80)\n","print(f\"Response message role: {response_message.role}\")\n","print(f\"Response message content: {response_message.content}\")\n","print(f\"Has tool calls? {response_message.tool_calls is not None}\")\n","print()\n","\n","if response_message.tool_calls:\n","    print(\"Tool calls requested by LLM:\")\n","    for tool_call in response_message.tool_calls:\n","        print(f\"  Tool call ID: {tool_call.id}\")\n","        print(f\"  Function name: {tool_call.function.name}\")\n","        print(f\"  Function arguments (JSON string): {tool_call.function.arguments}\")\n","        print(f\"  Parsed arguments: {json.loads(tool_call.function.arguments)}\")\n","    print()"]},{"cell_type":"markdown","id":"657dcafe","metadata":{"id":"657dcafe"},"source":["### Step 5: Execute the function call"]},{"cell_type":"code","execution_count":null,"id":"5df63741","metadata":{"id":"5df63741"},"outputs":[],"source":["print(\"=\" * 80)\n","print(\"STEP 5: Executing the function\")\n","print(\"=\" * 80)\n","\n","# The LLM wants to call a function - let's execute it\n","tool_call = response_message.tool_calls[0]\n","function_name = tool_call.function.name\n","function_args = json.loads(tool_call.function.arguments)\n","\n","print(f\"Function to call: {function_name}\")\n","print(f\"Arguments: {function_args}\")\n","print()\n","\n","# Actually execute the function\n","if function_name == \"calculate\":\n","    function_result = calculate(**function_args)\n","else:\n","    function_result = {\"error\": \"Unknown function\"}\n","\n","print(f\"Function result:\")\n","print(json.dumps(function_result, indent=2))\n","print()"]},{"cell_type":"markdown","id":"a1dd1958","metadata":{"id":"a1dd1958"},"source":["### Step 6: Add function result to conversation"]},{"cell_type":"code","execution_count":null,"id":"a7b8a963","metadata":{"id":"a7b8a963"},"outputs":[],"source":["print(\"=\" * 80)\n","print(\"STEP 6: Adding function result to conversation\")\n","print(\"=\" * 80)\n","\n","# First, add the assistant's message (which contains the tool call)\n","messages.append(response_message)\n","\n","# Then add the function result\n","messages.append({\n","    \"role\": \"tool\",\n","    \"tool_call_id\": tool_call.id,\n","    \"name\": function_name,\n","    \"content\": json.dumps(function_result)\n","})\n","\n","print(\"Updated conversation messages:\")\n","for i, msg in enumerate(messages):\n","    print(f\"\\nMessage {i}:\")\n","    if isinstance(msg, dict):\n","        print(f\"  Role: {msg['role']}\")\n","        if 'content' in msg and msg['content']:\n","            content = msg['content'][:100] + \"...\" if len(msg['content']) > 100 else msg['content']\n","            print(f\"  Content: {content}\")\n","    else:\n","        print(f\"  Role: {msg.role}\")\n","        if msg.content:\n","            content = msg.content[:100] + \"...\" if len(msg.content) > 100 else msg.content\n","            print(f\"  Content: {content}\")\n","        if msg.tool_calls:\n","            print(f\"  Tool calls: {len(msg.tool_calls)} function(s)\")\n","print()"]},{"cell_type":"markdown","id":"a4942616","metadata":{"id":"a4942616"},"source":["### Step 7: Get final response from LLM"]},{"cell_type":"code","execution_count":null,"id":"65ea01e0","metadata":{"id":"65ea01e0"},"outputs":[],"source":["print(\"=\" * 80)\n","print(\"STEP 7: Getting final response from LLM\")\n","print(\"=\" * 80)\n","\n","# Make another API call with the function result included\n","final_response = client.chat.completions.create(\n","    model=\"gpt-4o-mini\",\n","    messages=messages\n",")\n","\n","final_answer = final_response.choices[0].message.content\n","\n","print(f\"Final response to user:\")\n","print(final_answer)\n","print()\n","print(\"=\" * 80)\n","print()"]},{"cell_type":"code","execution_count":null,"id":"a79a6fbb","metadata":{"id":"a79a6fbb"},"outputs":[],"source":["82374923*93478234"]},{"cell_type":"markdown","id":"c047c826","metadata":{"id":"c047c826"},"source":["### Wrapping into a reusable function\n","\n","Now let's wrap this into a reusable function for convenience."]},{"cell_type":"code","execution_count":null,"id":"183bccc5","metadata":{"id":"183bccc5"},"outputs":[],"source":["def chat_with_calculator(user_message: str) -> str:\n","    \"\"\"\n","    Chat with the calculator bot (simplified version).\n","\n","    Args:\n","        user_message: User's question\n","\n","    Returns:\n","        Bot's response\n","    \"\"\"\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You are a helpful math assistant. Use calculate for precise arithmetic.\"},\n","        {\"role\": \"user\", \"content\": user_message}\n","    ]\n","\n","    # Step 1: Initial call\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages,\n","        tools=tools,\n","        tool_choice=\"auto\"\n","    )\n","\n","    response_message = response.choices[0].message\n","\n","    # If no tool calls, return the text response\n","    if not response_message.tool_calls:\n","        return response_message.content\n","\n","    # Step 2: Execute tool calls\n","    messages.append(response_message)\n","\n","    for tool_call in response_message.tool_calls:\n","        function_name = tool_call.function.name\n","        function_args = json.loads(tool_call.function.arguments)\n","\n","        if function_name == \"calculate\":\n","            function_result = calculate(**function_args)\n","        else:\n","            function_result = {\"error\": \"Unknown function\"}\n","\n","        messages.append({\n","            \"role\": \"tool\",\n","            \"tool_call_id\": tool_call.id,\n","            \"name\": function_name,\n","            \"content\": json.dumps(function_result)\n","        })\n","\n","    # Step 3: Get final response\n","    final_response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages\n","    )\n","\n","    return final_response.choices[0].message.content"]},{"cell_type":"markdown","id":"de131b96","metadata":{"id":"de131b96"},"source":["### Demo: Calculator bot in action"]},{"cell_type":"code","execution_count":null,"id":"f10ddd69","metadata":{"id":"f10ddd69"},"outputs":[],"source":["print(\"=\" * 80)\n","print(\"DEMO: Calculator bot in action\")\n","print(\"=\" * 80)\n","print()\n","\n","# Example 1: Large multiplication\n","print(\"User: What is 82374923 multiplied by 93478234?\")\n","response = chat_with_calculator(\"What is 82374923 multiplied by 93478234?\")\n","print(f\"Bot: {response}\")\n","print()\n","\n","print(\"-\" * 80)\n","print()\n","\n","# Example 2: Different operation\n","print(\"User: Calculate 12345 plus 67890\")\n","response = chat_with_calculator(\"Calculate 12345 plus 67890\")\n","print(f\"Bot: {response}\")\n","print()\n","\n","print(\"-\" * 80)\n","print()\n","\n","# Example 3: Division\n","print(\"User: What's 100 divided by 7?\")\n","response = chat_with_calculator(\"What's 100 divided by 7?\")\n","print(f\"Bot: {response}\")\n","print()\n","\n","print(\"=\" * 80)\n","print()"]},{"cell_type":"markdown","id":"5c6541b9","metadata":{"id":"5c6541b9"},"source":["## Part 4: Example 2 - Weather Bot with Real API\n","\n","Now let's build something that needs external data: a chatbot that can tell you\n","REAL weather information by calling the Open-Meteo API.\n","\n","**Open-Meteo API**: https://open-meteo.com/\n","- Free, no API key needed\n","- Provides current weather, forecasts, historical data\n","- We'll use their geocoding API to get coordinates, then weather data"]},{"cell_type":"markdown","id":"d56701b4","metadata":{"id":"d56701b4"},"source":["### Define the weather function (REAL API call)"]},{"cell_type":"code","execution_count":null,"id":"9d9bbddc","metadata":{"id":"9d9bbddc"},"outputs":[],"source":["def get_weather(location: str) -> dict:\n","    \"\"\"\n","    Get current weather for a location using Open-Meteo API.\n","\n","    This is a REAL function that makes REAL API calls!\n","\n","    Args:\n","        location: City name (e.g., \"College Park\", \"New York\")\n","\n","    Returns:\n","        Dictionary with temperature, weather description, wind speed, humidity\n","    \"\"\"\n","    # Step 1: Get coordinates for the location using geocoding API\n","    geocoding_url = \"https://geocoding-api.open-meteo.com/v1/search\"\n","    geocoding_params = {\n","        \"name\": location,\n","        \"count\": 1,\n","        \"language\": \"en\",\n","        \"format\": \"json\"\n","    }\n","\n","    geo_response = requests.get(geocoding_url, params=geocoding_params)\n","    geo_data = geo_response.json()\n","\n","    if \"results\" not in geo_data or len(geo_data[\"results\"]) == 0:\n","        return {\"error\": f\"Location '{location}' not found\"}\n","\n","    # Extract coordinates\n","    lat = geo_data[\"results\"][0][\"latitude\"]\n","    lon = geo_data[\"results\"][0][\"longitude\"]\n","    location_name = geo_data[\"results\"][0][\"name\"]\n","\n","    # Step 2: Get weather data for these coordinates\n","    weather_url = \"https://api.open-meteo.com/v1/forecast\"\n","    weather_params = {\n","        \"latitude\": lat,\n","        \"longitude\": lon,\n","        \"current\": \"temperature_2m,relative_humidity_2m,weather_code,wind_speed_10m\",\n","        \"temperature_unit\": \"fahrenheit\",\n","        \"wind_speed_unit\": \"mph\"\n","    }\n","\n","    weather_response = requests.get(weather_url, params=weather_params)\n","    weather_data = weather_response.json()\n","\n","    # Step 3: Parse and format the results\n","    current = weather_data[\"current\"]\n","\n","    # Weather code mapping (simplified)\n","    weather_codes = {\n","        0: \"Clear sky\", 1: \"Mainly clear\", 2: \"Partly cloudy\", 3: \"Overcast\",\n","        45: \"Foggy\", 48: \"Foggy\", 51: \"Light drizzle\", 53: \"Moderate drizzle\",\n","        55: \"Dense drizzle\", 61: \"Slight rain\", 63: \"Moderate rain\", 65: \"Heavy rain\",\n","        71: \"Slight snow\", 73: \"Moderate snow\", 75: \"Heavy snow\", 80: \"Rain showers\",\n","        81: \"Rain showers\", 82: \"Heavy rain showers\", 95: \"Thunderstorm\"\n","    }\n","\n","    weather_code = current.get(\"weather_code\", 0)\n","    weather_description = weather_codes.get(weather_code, \"Unknown\")\n","\n","    return {\n","        \"location\": location_name,\n","        \"temperature_f\": current[\"temperature_2m\"],\n","        \"weather\": weather_description,\n","        \"humidity\": current[\"relative_humidity_2m\"],\n","        \"wind_speed_mph\": current[\"wind_speed_10m\"]\n","    }\n","\n","\n","# Test our function independently first!\n","print(\"=\" * 80)\n","print(\"Testing the weather function directly (without LLM)\")\n","print(\"=\" * 80)\n","\n","weather = get_weather(\"College Park\")\n","print(f\"Weather in {weather['location']}:\")\n","print(f\"  Temperature: {weather['temperature_f']}°F\")\n","print(f\"  Conditions: {weather['weather']}\")\n","print(f\"  Humidity: {weather['humidity']}%\")\n","print(f\"  Wind Speed: {weather['wind_speed_mph']} mph\")\n","print()"]},{"cell_type":"markdown","id":"379f2182","metadata":{"id":"379f2182"},"source":["### Define weather tool and create bot function"]},{"cell_type":"code","execution_count":null,"id":"a8bd2919","metadata":{"id":"a8bd2919"},"outputs":[],"source":["# Define weather tool\n","weather_tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"get_weather\",\n","            \"description\": \"Get the current weather for a specific location. Use this when the user asks about weather conditions, temperature, or climate in a city.\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"location\": {\n","                        \"type\": \"string\",\n","                        \"description\": \"The city name, e.g., 'College Park', 'New York', 'San Francisco'\"\n","                    }\n","                },\n","                \"required\": [\"location\"]\n","            }\n","        }\n","    }\n","]\n","\n","\n","def chat_with_weather_bot(user_message: str) -> str:\n","    \"\"\"Chat with weather bot (same pattern as calculator).\"\"\"\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You are a helpful weather assistant. Use get_weather for current weather.\"},\n","        {\"role\": \"user\", \"content\": user_message}\n","    ]\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages,\n","        tools=weather_tools,\n","        tool_choice=\"auto\"\n","    )\n","\n","    response_message = response.choices[0].message\n","\n","    if not response_message.tool_calls:\n","        return response_message.content\n","\n","    messages.append(response_message)\n","\n","    for tool_call in response_message.tool_calls:\n","        function_name = tool_call.function.name\n","        function_args = json.loads(tool_call.function.arguments)\n","\n","        if function_name == \"get_weather\":\n","            function_result = get_weather(**function_args)\n","        else:\n","            function_result = {\"error\": \"Unknown function\"}\n","\n","        messages.append({\n","            \"role\": \"tool\",\n","            \"tool_call_id\": tool_call.id,\n","            \"name\": function_name,\n","            \"content\": json.dumps(function_result)\n","        })\n","\n","    final_response = client.chat.completions.create(\n","        model=\"gpt-4o-mini\",\n","        messages=messages\n","    )\n","\n","    return final_response.choices[0].message.content"]},{"cell_type":"markdown","id":"e68603b3","metadata":{"id":"e68603b3"},"source":["### Demo: Weather bot"]},{"cell_type":"code","execution_count":null,"id":"3699dbcb","metadata":{"id":"3699dbcb"},"outputs":[],"source":["print(\"=\" * 80)\n","print(\"DEMO: Weather bot\")\n","print(\"=\" * 80)\n","print()\n","\n","print(\"User: What's the weather like in Seattle?\")\n","response = chat_with_weather_bot(\"What's the weather like in Seattle?\")\n","print(f\"Bot: {response}\")\n","print()\n","\n","print(\"-\" * 80)\n","print()\n","\n","# This should trigger TWO function calls (Seattle and Miami)\n","print(\"User: Should I visit Seattle or Miami based on the weather?\")\n","response = chat_with_weather_bot(\"Should I visit Seattle or Miami based on the weather?\")\n","print(f\"Bot: {response}\")\n","print()\n","\n","print(\"=\" * 80)\n","print()"]},{"cell_type":"markdown","id":"3746c448","metadata":{"id":"3746c448"},"source":["## Part 5 (OPTIONAL): Example 3 - OpenFoodFacts Integration\n","\n","Remember OpenFoodFacts from Lecture 07? Let's give an LLM access to it!\n","\n","This shows how tool use can integrate with any API you've learned about."]},{"cell_type":"code","execution_count":null,"id":"d4056994","metadata":{"id":"d4056994"},"outputs":[],"source":["def get_nutrition_info(product_name: str) -> dict:\n","    \"\"\"\n","    Search for a product on OpenFoodFacts and return nutritional information.\n","\n","    Args:\n","        product_name: Name of the food product\n","\n","    Returns:\n","        Dictionary with nutritional information\n","    \"\"\"\n","    search_url = \"https://world.openfoodfacts.org/cgi/search.pl\"\n","    params = {\n","        \"search_terms\": product_name,\n","        \"page_size\": 1,\n","        \"json\": 1\n","    }\n","\n","    response = requests.get(search_url, params=params)\n","    data = response.json()\n","\n","    if data[\"count\"] == 0:\n","        return {\"error\": f\"Product '{product_name}' not found\"}\n","\n","    product = data[\"products\"][0]\n","    nutriments = product.get(\"nutriments\", {})\n","\n","    return {\n","        \"product_name\": product.get(\"product_name\", \"Unknown\"),\n","        \"brands\": product.get(\"brands\", \"Unknown\"),\n","        \"calories_per_100g\": nutriments.get(\"energy-kcal_100g\", \"N/A\"),\n","        \"fat_per_100g\": nutriments.get(\"fat_100g\", \"N/A\"),\n","        \"carbs_per_100g\": nutriments.get(\"carbohydrates_100g\", \"N/A\"),\n","        \"protein_per_100g\": nutriments.get(\"proteins_100g\", \"N/A\"),\n","        \"nutriscore\": product.get(\"nutriscore_grade\", \"N/A\").upper()\n","    }\n","\n","\n","# Test it\n","print(\"=\" * 80)\n","print(\"(OPTIONAL) Testing OpenFoodFacts function\")\n","print(\"=\" * 80)\n","print(json.dumps(get_nutrition_info(\"Nutella\"), indent=2))\n","print()\n","\n","# The tool definition and bot function would follow the same pattern..."]},{"cell_type":"markdown","id":"2b5a4e5f","metadata":{"id":"2b5a4e5f"},"source":["## Part 6: Multi-Tool Usage - Combining Everything\n","\n","### Multi-Tool Usage: The Power of Orchestration\n","\n","The real power of tool use: LLMs can orchestrate multiple tools!\n","\n","**Conceptual Example:**\n","If you give an LLM access to both weather and calculator tools, and ask:\n","\"If it's 85°F in Miami, what's that in Celsius?\"\n","\n","The LLM would:\n","1. Call get_weather(\"Miami\") to get actual temperature\n","2. Call calculate with the formula (F - 32) * 5/9\n","3. Synthesize: \"It's currently X°F in Miami, which equals Y°C\"\n","\n","**How it works:**\n","- Same pattern as before, but now tools list contains multiple functions\n","- LLM decides which tool(s) to use based on the user query\n","- May call multiple tools in sequence\n","- You still execute each function and send results back"]},{"cell_type":"markdown","id":"b9c82cba","metadata":{"id":"b9c82cba"},"source":["### Multi-Tool Usage: Combining Tools\n","\n","The real power of tool use: LLMs can use multiple tools together!\n","\n","**Example 1: Compare temperatures in two cities**\n","- Query: \"Compare temperatures in Seattle and Miami, which is warmer?\"\n","- LLM would:\n","  1. Call get_weather('Seattle')\n","  2. Call get_weather('Miami')\n","  3. Compare results and answer\n","\n","**Example 2: Temperature conversion**\n","- Query: \"If Seattle is 58°F, convert that to Celsius\"\n","- LLM would:\n","  1. Call get_weather('Seattle') to confirm temperature\n","  2. Call calculate(58, 32, 'subtract') → 26\n","  3. Call calculate(26, 5, 'multiply') → 130\n","  4. Call calculate(130, 9, 'divide') → 14.44°C\n","\n","The pattern is the same, just with more tools available!"]},{"cell_type":"markdown","id":"26b5c0a3","metadata":{"id":"26b5c0a3"},"source":["## Part 7: What Makes Tool Use Possible?\n","\n","### The Technology Behind Tool Use\n","\n","How do LLMs \"learn\" to use tools? They weren't explicitly trained on function calling!\n","\n","### Three Key Enabling Factors\n","\n","**1. Reasoning Capacity**\n","- Modern LLMs have strong reasoning abilities\n","- Can understand: \"I need external information to answer this\"\n","- Can plan: \"First get weather for A, then B, then compare\"\n","- Can interpret function descriptions and match them to user needs\n","\n","**2. Long Context Windows**\n","- Early models: ~4K tokens context\n","- Modern models: 128K - 1M+ tokens\n","- Allows LLMs to see:\n","  - Tool definitions\n","  - Conversation history\n","  - Function results\n","  - User query\n","  All at once!\n","\n","**3. Instruction Following**\n","- LLMs trained to follow complex instructions\n","- Can understand: \"When you need information, output JSON with function name and args\"\n","- Can adapt to different tool formats and conventions"]},{"cell_type":"markdown","id":"2b64da22","metadata":{"id":"2b64da22"},"source":["### How LLMs Learn Tool Use\n","\n","**Through Alignment Training:**\n","\n","1. **Fine-tuning on tool use examples**\n","   - Trained on millions of examples of function calling\n","   - Learns pattern: Question → Recognize need → Call function → Use result\n","\n","2. **Reinforcement Learning from Human Feedback (RLHF)**\n","   - Reward correct tool usage\n","   - Penalize making up information when a tool is available\n","   - Penalize calling wrong function or wrong parameters\n","\n","3. **Synthetic data generation**\n","   - Generate diverse tool-use scenarios\n","   - Cover edge cases and error handling\n","\n","**Important**: The LLM doesn't actually \"run\" code or \"make\" API calls.\n","It outputs JSON that YOUR code interprets and executes. This is key for security!\n","\n","### Real-World Agent Examples\n","\n","**1. ChatGPT**\n","- Web search, code interpreter, image generation, DALL-E\n","- LLM orchestrates which plugin to use when\n","\n","**2. Claude Code**\n","- File operations, terminal commands, code editing\n","- Decides when to read files, when to edit, when to run commands\n","\n","**3. Corporate AI assistants**\n","- Access to internal knowledge bases (documents, wikis)\n","- Integration with company systems (HR, IT, CRM)\n","- Example: \"What's the status of my PTO request?\"\n","  → Queries HR system → Returns answer\n","\n","**4. Customer service bots**\n","- Order tracking, inventory lookup, refund processing\n","- Orchestrate multiple backend systems\n","\n","**Key insight**: Tool use + reasoning capacity + long context = capable AI agents"]},{"cell_type":"markdown","id":"ccce994f","metadata":{"id":"ccce994f"},"source":["## Part 8: Best Practices & Wrap-up\n","\n","### Key Considerations\n","\n","**1. Security**\n","- You control what executes - LLM only suggests\n","- Always validate inputs before execution\n","- Restrict tools to safe operations only\n","\n","**2. Cost & Reliability**\n","- Each tool call = multiple API requests\n","- LLMs may occasionally call wrong function\n","- Test functions independently first\n","\n","**3. Error Handling**\n","- Always handle errors gracefully\n","- Return clear error messages to LLM\n","- LLM can often recover from errors\n","\n","### Summary: The Tool Use Pattern\n","\n","1. **Define tools**: Create function + JSON specification\n","2. **LLM decides**: Model determines if/when/how to use tools\n","3. **You execute**: Your code runs the actual function\n","4. **LLM synthesizes**: Model incorporates results into response\n","\n","This pattern transforms LLMs from text generators into capable agents!"]},{"cell_type":"markdown","id":"e08e6437","metadata":{"id":"e08e6437"},"source":["## Key takeaways:\n","1. Tool use gives LLMs access to external capabilities\n","2. The pattern: Define → LLM decides → You execute → LLM synthesizes\n","3. JSON is central to tool definitions and results\n","4. Reasoning + Long context + Instruction following = Tool use\n","5. Tool use is what makes LLMs into agents\n","\n","### Next Steps\n","\n","- Experiment with these examples\n","- Spot tool calling in using ChatGPT\n","- Think about what tasks could benefit from tool use\n","- Explore OpenAI's function calling documentation"]}],"metadata":{"kernelspec":{"display_name":"ds","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"colab":{"provenance":[],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}